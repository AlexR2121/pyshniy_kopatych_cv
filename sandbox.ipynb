{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8adc81c-d3ca-4d8f-8261-5702c75daf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import subprocess\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b808176d-76f6-4da6-9511-01d76846983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec2fa77-92ab-483b-b167-8b93041c01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>Start_</th>\n",
       "      <th>End_</th>\n",
       "      <th>Special_transport_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>00:00:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>00:00:12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File  Label    Start_      End_  Special_transport_\n",
       "0     1      1  00:00:06  00:00:14                   1\n",
       "1     2      1  00:00:00  00:00:58                   1\n",
       "2     3      0  00:00:00  00:00:00                   0\n",
       "3     4      1  00:00:03  00:00:13                   0\n",
       "4     5      1  00:00:02  00:00:12                   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../Downloads/Telegram Desktop/разметка.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290c7886-9242-4dc3-8877-cf3ae1c6a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = '../Downloads/dtp_images'\n",
    "subprocess.Popen(f\"mkdir {save_path}\").wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec543b2-624b-4b93-a0f5-17db78982a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae97b82-3bde-43f0-9ca6-dda1ff2b0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_test_data = train_test_split(data, test_size = 10, stratify = data.Label, random_state = rs)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size = 5, stratify = val_test_data.Label, random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7a6c86-6262-479e-a86a-9003db5f0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "X_val, y_val = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f28a944d-fca1-4568-be02-92121321422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_videos(resize_shape = (224, 224), data_dir = '../Downloads/Онлайн этап/'):\n",
    "    for filename in list(os.walk(data_dir))[0][2]:\n",
    "        vidcap = cv2.VideoCapture(data_dir+filename)\n",
    "        int_filename = int(filename.split('.')[0])\n",
    "        if int_filename in train_data.File.values:\n",
    "            target_data = X_train\n",
    "            y_train.append(train_data[train_data.File==int_filename].Label)\n",
    "        elif int_filename in val_data.File.values:\n",
    "            target_data = X_val\n",
    "            y_val.append(val_data[val_data.File==int_filename].Label)\n",
    "        else:\n",
    "            continue\n",
    "        target_data.append([])\n",
    "        count = 0\n",
    "        while True:\n",
    "            ret, frame = vidcap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if not count % 10:\n",
    "                resized_frame = cv2.resize(frame, resize_shape, interpolation = cv2.INTER_AREA)\n",
    "                #cv2.imwrite(f\"{save_path}/{filename.split('.')[0]}_{count}.png\", resized_frame)\n",
    "                target_data[-1].append(resized_frame)\n",
    "            count += 1\n",
    "        vidcap.release()\n",
    "        target_data[-1] = np.array(target_data[-1])\n",
    "        \n",
    "        print(f\"{filename} has been processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827d58cd-4546-452d-b1f7-d187fe4c97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.mp4 has been processed\n",
      "11.mp4 has been processed\n",
      "12.mp4 has been processed\n",
      "13.mp4 has been processed\n",
      "14.mp4 has been processed\n",
      "15.mp4 has been processed\n",
      "16.mp4 has been processed\n",
      "17.mp4 has been processed\n",
      "18.mp4 has been processed\n",
      "19.mp4 has been processed\n",
      "2.mp4 has been processed\n",
      "20.mp4 has been processed\n",
      "21.mp4 has been processed\n",
      "22.mp4 has been processed\n",
      "23.mp4 has been processed\n",
      "24.mp4 has been processed\n",
      "26.mp4 has been processed\n",
      "27.mp4 has been processed\n",
      "28.mp4 has been processed\n",
      "3.mp4 has been processed\n",
      "31.mp4 has been processed\n",
      "32.mp4 has been processed\n",
      "33.mp4 has been processed\n",
      "34.mp4 has been processed\n",
      "35.mp4 has been processed\n",
      "36.mp4 has been processed\n",
      "37.mp4 has been processed\n",
      "38.mp4 has been processed\n",
      "39.mp4 has been processed\n",
      "4.mp4 has been processed\n",
      "40.mp4 has been processed\n",
      "41.mp4 has been processed\n",
      "42.mp4 has been processed\n",
      "43.mp4 has been processed\n",
      "44.mp4 has been processed\n",
      "45.mp4 has been processed\n",
      "46.mp4 has been processed\n",
      "47.mp4 has been processed\n",
      "48.mp4 has been processed\n",
      "49.mp4 has been processed\n",
      "5.mp4 has been processed\n",
      "50.mp4 has been processed\n",
      "6.mp4 has been processed\n",
      "8.mp4 has been processed\n",
      "9.mp4 has been processed\n"
     ]
    }
   ],
   "source": [
    "preprocess_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc81b95-2144-47d0-a39d-34a205241920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(map(len, X_train))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd902d2-b4d2-41c1-831c-61663c70d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, ResNet152V2 \n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed, GRU, Dense, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e0c9ca3-561e-4c1b-900f-64786de376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        X_train, maxlen=max_len, dtype='float16', padding='pre',\n",
    "        truncating='pre', value=0.0\n",
    "    )\n",
    "X_val = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        X_val, maxlen=max_len, dtype='float16', padding='pre',\n",
    "        truncating='pre', value=0.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5922418-9217-4d5d-8c16-8e5602d67536",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a441f34b-b77f-4304-881a-3492d7711202",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet152V2(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e02703ea-6614-4d48-ae1b-7f14e2bb7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f14592d1-700a-466c-8bb9-11d96baf39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape = (max_len, 224, 224, 3), batch_size = 4)\n",
    "resnet = TimeDistributed(base_model)(inp)\n",
    "rnn = Bidirectional(GRU(64, return_sequences = True))(resnet)\n",
    "rnn2 = Bidirectional(GRU(32))(rnn)\n",
    "x = Dense(100, activation = 'relu')(rnn2)\n",
    "otput = Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b0b0269-e96d-4fd7-ab3c-b2fb884c7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=otput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b379512-a876-47e6-a688-743229e8939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "443e874a-d143-4f39-b245-e67b776714fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(4, 389, 224, 224, 3)]   0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (4, 389, 1000)           60380648  \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (4, 389, 128)            409344    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (4, 64)                  31104     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (4, 100)                  6500      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (4, 1)                    101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,827,697\n",
      "Trainable params: 447,049\n",
      "Non-trainable params: 60,380,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05c40ce0-8d58-4e95-8e6d-529a47eff43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([i.values for i in y_train]).ravel()\n",
    "y_val = np.array([i.values for i in y_val]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a908a193-4a74-4e6c-932c-a032046bdb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0bfee25-6046-41b6-b9a9-47d81993a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, X: np.array, y: np.array, batch_size: int = 4):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def get_next_batch(self) -> tuple:\n",
    "        indices = np.arange(len(self.X))\n",
    "        np.random.shuffle(indices)\n",
    "        batch_begin = 0\n",
    "        while batch_begin < len(self.X):\n",
    "            batch_indices = indices[batch_begin : batch_begin+self.batch_size]\n",
    "            batch = tf.constant(self.X[(batch_indices)])\n",
    "            labels = tf.constant(self.y[(batch_indices)])\n",
    "            batch_begin += self.batch_size\n",
    "            yield batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e730bf55-cb29-408f-917b-b3773a076b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = BatchGenerator(X_train, y_train)\n",
    "val_generator = BatchGenerator(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452a5abf-ec56-432d-86fe-9e9ad01f1b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "     10/Unknown - 1095s 109s/step - loss: 0.6785 - accuracy: 0.6000"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5060/3822007291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\cv_car_acccidents\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5060/1242403496.py\u001b[0m in \u001b[0;36mget_next_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mbatch_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_begin\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_begin\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mbatch_begin\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_generator.get_next_batch(), epochs=3, validation_data=val_generator.get_next_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c16d7-d2b0-4888-a006-cd1f59acc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = TimeDistributed(ResNet152V2(weights='imagenet'))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "391c8f2e-c9f7-4f53-93aa-1d0e616336f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.applications.resnet_v2.preprocess_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b4445dc-7d23-4b67-84f2-8575f9507add",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = tf.keras.applications.resnet_v2.preprocess_input(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc72ea-3644-417d-a5f7-2fc06044cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "# from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "927902f2-01d5-4f5f-aacc-6a915b67af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet_v2.ResNet152V2(\n",
    "    include_top=True, weights=None, input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=2,\n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c03345-ee71-4b9e-84cd-b833eb9bc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab4c813d-6144-4c7d-85c8-bb01232425b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19908/424024344.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\cv_car_acccidents\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model.fit(x, y_train, epochs = 5, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe33585-bb91-4e36-9c91-8ffc0901b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a91063-a0d5-4bfd-92fb-d8a6e8eaa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_from_time(x):\n",
    "    return x.second*FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5af80ea-822c-4df0-90d5-e88d2137c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Start_frame'] = data['Start_'].apply(get_frame_from_time)\n",
    "data['End_frame'] = data['End_'].apply(get_frame_from_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "225aa0ea-eb36-4788-832b-903aecb3d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "      <th>Start_</th>\n",
       "      <th>End_</th>\n",
       "      <th>Special_transport_</th>\n",
       "      <th>Start_frame</th>\n",
       "      <th>End_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>00:00:14</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>00:00:12</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File  Label    Start_      End_  Special_transport_  Start_frame  End_frame\n",
       "0     1      1  00:00:06  00:00:14                   1          180        420\n",
       "1     2      1  00:00:00  00:00:58                   1            0       1740\n",
       "2     3      0  00:00:00  00:00:00                   0            0          0\n",
       "3     4      1  00:00:03  00:00:13                   0           90        390\n",
       "4     5      1  00:00:02  00:00:12                   1           60        360"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81e4f5f2-c339-417b-89aa-fefc670e2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56da981e-224a-443b-8076-4874815b043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 51):\n",
    "    frames_count = 0\n",
    "    for filename in list(os.walk(save_path))[0][2]:\n",
    "        if filename.split('_')[0] == str(i):\n",
    "            frames_count += 1\n",
    "    lengths.append(frames_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e287885-1bb5-44df-8776-102b578dd8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3884"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b286f947-e879-4f16-8c89-977a88f0f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927a6e1c-2281-489f-a298-b28db80cfed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_test_data = train_test_split(data, test_size = 10, stratify = data.Label)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size = 5, stratify = val_test_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62075c64-4e3f-4da4-834a-c1147c877121",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "val_dict = {}\n",
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058c283-e8e8-4102-80d1-f5fe3a763391",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in list(os.walk('../Downloads/dtp_images'))[0][2]:\n",
    "    video_name = filename.split('_')[0]\n",
    "    if video_name in train_data.File.values:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c080b0-9f7e-460e-93f5-80846ad109dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 51):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba0a7eb-3305-420f-9481-b733906ae4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = cv2.imread('../Downloads/dtp_images/1_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "480278f0-01e0-4488-94f2-a51e815a9858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 62,  62,  62],\n",
       "        [ 44,  44,  44],\n",
       "        [ 38,  38,  38],\n",
       "        ...,\n",
       "        [133, 133, 133],\n",
       "        [134, 134, 134],\n",
       "        [132, 132, 132]],\n",
       "\n",
       "       [[ 50,  50,  50],\n",
       "        [ 44,  44,  44],\n",
       "        [ 38,  38,  38],\n",
       "        ...,\n",
       "        [136, 136, 136],\n",
       "        [137, 137, 137],\n",
       "        [133, 133, 133]],\n",
       "\n",
       "       [[ 48,  48,  48],\n",
       "        [ 43,  43,  43],\n",
       "        [ 38,  38,  38],\n",
       "        ...,\n",
       "        [136, 136, 136],\n",
       "        [138, 138, 138],\n",
       "        [135, 135, 135]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 18,  18,  18],\n",
       "        [ 19,  19,  19],\n",
       "        [ 24,  24,  24],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]],\n",
       "\n",
       "       [[ 19,  19,  19],\n",
       "        [ 19,  19,  19],\n",
       "        [ 22,  22,  22],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]],\n",
       "\n",
       "       [[ 20,  20,  20],\n",
       "        [ 19,  19,  19],\n",
       "        [ 22,  22,  22],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e5fb6b4-521b-4ff9-88b6-e29c9ee3108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = {0:[], 1:[]}\n",
    "for filename in list(os.walk(save_path))[0][2]:\n",
    "    image_name = filename.split('_')\n",
    "    video_name = image_name[0]\n",
    "    frame_number = image_name[1].split('.')[0]\n",
    "    if data.loc[int(video_name), 'Label']:\n",
    "        label = 1 if data.loc[int(video_name), 'Start_frame'] < int(frame_number) < data.loc[int(video_name), 'End_frame'] else 0\n",
    "    else:\n",
    "        label = 0\n",
    "    data_labels[label].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40650134-2dcc-430d-b6a2-e203cca863ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76ab1de7-abfb-4e36-ba6c-adef0b62fbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41728, 6310]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(data_labels[key]) for key in data_labels.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05c94f5b-88b6-467d-9992-37e876fe5aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43256"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21697+7068+12088+2403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73fea61-a47f-49b5-9211-ddfd968d75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('../Downloads/Онлайн этап/1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6b1c68-95a2-4d3a-a01c-a437d7adb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, image = vidcap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebd47920-b85b-43ae-a587-730dabfd412b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 67,  67,  67],\n",
       "        [ 66,  66,  66],\n",
       "        [ 60,  60,  60],\n",
       "        ...,\n",
       "        [133, 133, 133],\n",
       "        [130, 130, 130],\n",
       "        [132, 132, 132]],\n",
       "\n",
       "       [[ 71,  71,  71],\n",
       "        [ 69,  69,  69],\n",
       "        [ 55,  55,  55],\n",
       "        ...,\n",
       "        [135, 135, 135],\n",
       "        [132, 132, 132],\n",
       "        [133, 133, 133]],\n",
       "\n",
       "       [[ 59,  59,  59],\n",
       "        [ 58,  58,  58],\n",
       "        [ 48,  48,  48],\n",
       "        ...,\n",
       "        [137, 137, 137],\n",
       "        [135, 135, 135],\n",
       "        [133, 133, 133]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 19,  19,  19],\n",
       "        [ 19,  19,  19],\n",
       "        [ 19,  19,  19],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]],\n",
       "\n",
       "       [[ 20,  20,  20],\n",
       "        [ 20,  20,  20],\n",
       "        [ 20,  20,  20],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]],\n",
       "\n",
       "       [[ 20,  20,  20],\n",
       "        [ 20,  20,  20],\n",
       "        [ 20,  20,  20],\n",
       "        ...,\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248],\n",
       "        [248, 248, 248]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a79d8c-1186-46b5-a296-89f014872ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(image, size, cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f41154-22fc-4e86-b581-89e440a8ff2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d48e8-75b2-4a3c-9a9b-5dce14ba7ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
